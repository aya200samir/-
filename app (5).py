import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import arabic_reshaper
from bidi.algorithm import get_display
from textblob import TextBlob
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from scipy import stats
import networkx as nx
import requests
from streamlit_lottie import st_lottie
import warnings
import os
from datetime import datetime
import xgboost as xgb
warnings.filterwarnings('ignore')

# -------------------------------
# 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ØªØµÙ…ÙŠÙ…
# -------------------------------
st.set_page_config(
    page_title="Ø§Ù„Ø±Ù‚ÙŠØ¨ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙƒÙŠ - AutoML",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ø¯Ø§Ù„Ø© Ù„ØªØ­Ù…ÙŠÙ„ Lottie animation
def load_lottieurl(url):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

lottie_ai = load_lottieurl("https://assets9.lottiefiles.com/packages/lf20_p8bfn5sw.json")
lottie_clean = load_lottieurl("https://assets9.lottiefiles.com/packages/lf20_qwyjxnmr.json")

# Ø­Ù‚Ù† CSS Ù…Ø®ØµØµ
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@400;600;800&display=swap');
    * {
        font-family: 'Cairo', sans-serif;
    }
    .stApp {
        background: radial-gradient(circle at 10% 20%, rgba(0,0,0,1) 0%, rgba(20,30,48,1) 90%);
        color: #e0e0e0;
    }
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

    .glass-card {
        background: rgba(20, 30, 48, 0.4);
        backdrop-filter: blur(15px);
        border-radius: 20px;
        padding: 20px;
        border: 1px solid rgba(0, 242, 254, 0.2);
        box-shadow: 0 8px 32px 0 rgba(0,0,0,0.5);
        transition: all 0.3s ease;
        margin-bottom: 20px;
    }
    .glass-card:hover {
        transform: translateY(-5px);
        border: 1px solid rgba(0, 242, 254, 0.8);
        box-shadow: 0 0 20px rgba(0, 242, 254, 0.4);
    }

    .title {
        font-size: 48px;
        font-weight: 800;
        background: linear-gradient(45deg, #00f2fe, #4facfe);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 0;
    }
    .subtitle {
        color: #8892b0;
        font-size: 20px;
        margin-top: -10px;
        margin-bottom: 30px;
    }
    </style>
""", unsafe_allow_html=True)

# -------------------------------
# 2. Ø§Ù„Ù‡ÙŠØ¯Ø±
# -------------------------------
col1, col2 = st.columns([1, 4])
with col1:
    if lottie_ai:
        st_lottie(lottie_ai, height=150, key="ai_anim")
with col2:
    st.markdown("<p class='title'>Ø§Ù„Ø±Ù‚ÙŠØ¨ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙƒÙŠ - AutoML</p>", unsafe_allow_html=True)
    st.markdown("<p class='subtitle'>Ù…Ù†ØµØ© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…ØªÙƒØ§Ù…Ù„Ø© Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø´Ø§Ø°Ø©</p>", unsafe_allow_html=True)

st.markdown("---")

# -------------------------------
# 3. ÙƒÙ„Ø§Ø³ Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
# -------------------------------
class AutoDataCleaner:
    def __init__(self, df):
        self.df = df.copy()
        self.cleaning_report = []
        self.original_shape = df.shape
        
    def clean(self):
        """ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
        
        # 1. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„ÙØ§Ø±ØºØ© ØªÙ…Ø§Ù…Ø§Ù‹
        empty_cols = self.df.columns[self.df.isnull().all()].tolist()
        if empty_cols:
            self.df = self.df.drop(columns=empty_cols)
            self.cleaning_report.append(f"âœ… ØªÙ… Ø¥Ø²Ø§Ù„Ø© {len(empty_cols)} Ø¹Ù…ÙˆØ¯ ÙØ§Ø±Øº ØªÙ…Ø§Ù…Ø§Ù‹")
        
        # 2. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
        duplicates = self.df.duplicated().sum()
        if duplicates > 0:
            self.df = self.df.drop_duplicates()
            self.cleaning_report.append(f"âœ… ØªÙ… Ø¥Ø²Ø§Ù„Ø© {duplicates} ØµÙ Ù…ÙƒØ±Ø±")
        
        # 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
        for col in self.df.columns:
            missing = self.df[col].isnull().sum()
            if missing > 0:
                if self.df[col].dtype in ['int64', 'float64']:
                    # Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: Ù†Ù…Ù„Ø£ Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·
                    self.df[col].fillna(self.df[col].mean(), inplace=True)
                    self.cleaning_report.append(f"âœ… Ø§Ù„Ø¹Ù…ÙˆØ¯ {col}: ØªÙ… Ù…Ù„Ø¡ {missing} Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ù„Ù…ØªÙˆØ³Ø·")
                else:
                    # Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©: Ù†Ù…Ù„Ø£ Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
                    self.df[col].fillna(self.df[col].mode()[0] if not self.df[col].mode().empty else 'Unknown', inplace=True)
                    self.cleaning_report.append(f"âœ… Ø§Ù„Ø¹Ù…ÙˆØ¯ {col}: ØªÙ… Ù…Ù„Ø¡ {missing} Ù‚ÙŠÙ…Ø© Ù…ÙÙ‚ÙˆØ¯Ø© Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹")
        
        # 4. ÙƒØ´Ù ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© (Outliers) Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
        numeric_cols = self.df.select_dtypes(include=[np.number]).columns
        outlier_count = 0
        for col in numeric_cols:
            Q1 = self.df[col].quantile(0.25)
            Q3 = self.df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = self.df[(self.df[col] < lower_bound) | (self.df[col] > upper_bound)]
            if len(outliers) > 0:
                outlier_count += len(outliers)
                # ÙŠÙ…ÙƒÙ† Ø§Ø®ØªÙŠØ§Ø± Ø¥Ù…Ø§ Ø§Ù„Ø­Ø°Ù Ø£Ùˆ Ø§Ù„ØªØ­Ø°ÙŠØ± ÙÙ‚Ø· - Ù‡Ù†Ø§ Ø³Ù†Ø­ØªÙØ¸ Ø¨Ù‡Ø§ Ù…Ø¹ ØªØ­Ø°ÙŠØ±
                self.cleaning_report.append(f"âš ï¸ Ø§Ù„Ø¹Ù…ÙˆØ¯ {col}: ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(outliers)} Ù‚ÙŠÙ…Ø© Ù…ØªØ·Ø±ÙØ© (Ù…Ø­ØªÙØ¸ Ø¨Ù‡Ø§ Ù„Ù„ØªØ­Ù„ÙŠÙ„)")
        
        # 5. ØªÙˆØ­ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„Ù†ØµÙˆØµ (Lowercase) Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©
        text_cols = self.df.select_dtypes(include=['object']).columns
        for col in text_cols:
            try:
                self.df[col] = self.df[col].astype(str).str.strip()
                self.cleaning_report.append(f"âœ… Ø§Ù„Ø¹Ù…ÙˆØ¯ {col}: ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©")
            except:
                pass
        
        return self.df
    
    def get_report(self):
        report = f"ğŸ“Š ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ:\n"
        report += f"- Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ø£ØµÙ„ÙŠØ©: {self.original_shape}\n"
        report += f"- Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ: {self.df.shape}\n"
        for item in self.cleaning_report:
            report += f"  {item}\n"
        return report

# -------------------------------
# 4. ÙƒÙ„Ø§Ø³ Ù„Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
# -------------------------------
class AutoML:
    def __init__(self, df):
        self.df = df.copy()
        self.model = None
        self.features = []
        self.target = None
        self.encoders = {}
        
    def prepare_data(self):
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙƒÙ†Ù…Ø·
        self.features = self.df.select_dtypes(include=[np.number]).columns.tolist()
        
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¹Ù…ÙˆØ¯ "is_suspicious" Ø£Ùˆ "outlier" Ù†Ø³ØªØ®Ø¯Ù…Ù‡ ÙƒÙ€ target
        target_cols = ['is_suspicious', 'outlier', 'label', 'target', 'class']
        for col in target_cols:
            if col in self.df.columns:
                self.target = col
                if col in self.features:
                    self.features.remove(col)
                break
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ targetØŒ Ù†ØµÙ†Ø¹ ÙˆØ§Ø­Ø¯ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Isolation Forest
        if self.target is None and len(self.features) >= 2:
            iso_forest = IsolationForest(contamination=0.1, random_state=42)
            self.df['auto_target'] = iso_forest.fit_predict(self.df[self.features])
            self.df['auto_target'] = (self.df['auto_target'] == -1).astype(int)
            self.target = 'auto_target'
            self.features = [f for f in self.features if f != 'auto_target']
        
        return len(self.features) > 0 and self.target is not None
    
    def train_xgboost(self):
        """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost"""
        
        if not self.prepare_data():
            return None, "Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X = self.df[self.features].fillna(0)
        y = self.df[self.target]
        
        # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        self.model = xgb.XGBClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42,
            use_label_encoder=False,
            eval_metric='logloss'
        )
        
        self.model.fit(X_train, y_train)
        
        # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        y_pred = self.model.predict(X_test)
        accuracy = (y_pred == y_test).mean()
        
        # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
        feature_importance = pd.DataFrame({
            'feature': self.features,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        # ØªÙˆÙ‚Ø¹ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.df['ml_score'] = self.model.predict_proba(X)[:, 1] * 100
        
        return {
            'accuracy': accuracy,
            'feature_importance': feature_importance,
            'predictions': self.df[['ml_score'] + self.features + [self.target]].copy()
        }, None
    
    def get_feature_importance_plot(self, feature_importance):
        """Ø±Ø³Ù… Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
        fig = px.bar(feature_importance.head(10), 
                     x='importance', y='feature', 
                     orientation='h',
                     title='Ø£Ù‡Ù… 10 Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬',
                     color='importance',
                     color_continuous_scale='viridis')
        fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', 
                         paper_bgcolor='rgba(0,0,0,0)',
                         font=dict(color='white'))
        return fig

# -------------------------------
# 5. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# -------------------------------
with st.sidebar:
    st.markdown("<h2 style='text-align: center;'>âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø°ÙƒÙŠØ©</h2>", unsafe_allow_html=True)
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù CSV Ù„Ù„ØªØ¯Ø±ÙŠØ¨", type=["csv"])
    
    if uploaded_file is not None:
        # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        df_raw = pd.read_csv(uploaded_file)
        st.success(f"âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­! {df_raw.shape[0]} ØµÙØŒ {df_raw.shape[1]} Ø¹Ù…ÙˆØ¯")
        
        # Ø®ÙŠØ§Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        st.markdown("---")
        st.markdown("### ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        auto_clean = st.checkbox("ØªØ´ØºÙŠÙ„ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ", value=True)
        
        # Ø®ÙŠØ§Ø± Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        st.markdown("---")
        st.markdown("### ğŸ¤– Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ")
        auto_train = st.checkbox("ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (XGBoost)", value=True)
        
        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„ØªØ´ØºÙŠÙ„
        st.markdown("---")
        run_button = st.button("ğŸš€ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", type="primary", use_container_width=True)
    else:
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ù…Ù„Ù
        st.info("ğŸ“Œ ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù CSV Ù„Ù„Ø¨Ø¯Ø¡")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø¹Ø±Ø¶
        np.random.seed(42)
        n_samples = 200
        df_raw = pd.DataFrame({
            'case_id': range(1, n_samples+1),
            'judge': np.random.choice(['Ù‚Ø§Ø¶ÙŠ Ø£Ø­Ù…Ø¯', 'Ù‚Ø§Ø¶ÙŠ Ø®Ø§Ù„Ø¯', 'Ù‚Ø§Ø¶ÙŠ Ø³Ø§Ø±Ø©', 'Ù‚Ø§Ø¶ÙŠ Ù„ÙŠÙ„Ù‰', 'Ù‚Ø§Ø¶ÙŠ Ù…Ø­Ù…Ø¯'], n_samples),
            'lawyer': np.random.choice(['Ù…Ø­Ø§Ù…ÙŠ Ø¹Ù„ÙŠ', 'Ù…Ø­Ø§Ù…ÙŠ Ù†ÙˆØ±', 'Ù…Ø­Ø§Ù…ÙŠ Ø¹Ù…Ø±', 'Ù…Ø­Ø§Ù…ÙŠ Ù‡Ù†Ø¯', 'Ù…Ø­Ø§Ù…ÙŠ Ø³Ø§Ù…Ø±'], n_samples),
            'case_type': np.random.choice(['Ø¬Ù†Ø§Ø¦ÙŠ', 'Ù…Ø¯Ù†ÙŠ', 'Ø¥Ø¯Ø§Ø±ÙŠ', 'Ø£Ø³Ø±Ø©'], n_samples),
            'duration_days': np.random.gamma(shape=2, scale=30, size=n_samples).astype(int) + 10,
            'amount': np.random.uniform(1000, 100000, n_samples).round(2),
            'evidence_strength': np.random.uniform(0, 10, n_samples).round(1),
            'sentence_severity': np.random.choice([0, 1, 2, 3], n_samples, p=[0.2,0.3,0.3,0.2]),
            'case_text': [f"Ù†Øµ Ø§Ù„Ù‚Ø¶ÙŠØ© Ø±Ù‚Ù… {i} ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ØªÙØ§ØµÙŠÙ„..." for i in range(1, n_samples+1)]
        })
        
        # Ø¥Ø¶Ø§ÙØ© Ø¨Ø¹Ø¶ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù„ØªØ¬Ø±Ø¨Ø©
        df_raw.loc[0:5, 'amount'] = np.nan
        df_raw.loc[10:15, 'evidence_strength'] = np.nan
        
        auto_clean = True
        auto_train = True
        run_button = True

# -------------------------------
# 6. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# -------------------------------
if run_button:
    # ØªÙ‚Ø¯Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # Ø®Ø·ÙˆØ© 1: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if auto_clean:
        status_text.text("ğŸ§¹ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        progress_bar.progress(20)
        
        cleaner = AutoDataCleaner(df_raw)
        df_cleaned = cleaner.clean()
        cleaning_report = cleaner.get_report()
        
        with st.expander("ğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†Ø¸ÙŠÙ", expanded=True):
            st.text(cleaning_report)
    else:
        df_cleaned = df_raw.copy()
    
    # Ø®Ø·ÙˆØ© 2: Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    status_text.text("ğŸ“Š Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    progress_bar.progress(40)
    
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
        st.markdown("### ğŸ“‹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ")
        st.dataframe(df_cleaned.head(10), use_container_width=True)
        st.markdown("</div>", unsafe_allow_html=True)
    
    with col2:
        st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
        st.markdown("### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø³Ø±ÙŠØ¹Ø©")
        st.write(f"- Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ: {df_cleaned.shape[0]}")
        st.write(f"- Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©: {df_cleaned.shape[1]}")
        st.write(f"- Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: {len(df_cleaned.select_dtypes(include=[np.number]).columns)}")
        st.write(f"- Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©: {len(df_cleaned.select_dtypes(include=['object']).columns)}")
        st.markdown("</div>", unsafe_allow_html=True)
    
    # Ø®Ø·ÙˆØ© 3: Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
    if auto_train:
        status_text.text("ğŸ¤– Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost...")
        progress_bar.progress(60)
        
        automl = AutoML(df_cleaned)
        results, error = automl.train_xgboost()
        
        if results:
            # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            col1, col2, col3 = st.columns(3)
            with col1:
                st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
                st.metric("ğŸ¯ Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬", f"{results['accuracy']:.2%}")
                st.markdown("</div>", unsafe_allow_html=True)
            
            with col2:
                st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
                st.metric("ğŸ“ˆ Ø¹Ø¯Ø¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©", len(automl.features))
                st.markdown("</div>", unsafe_allow_html=True)
            
            with col3:
                st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
                high_risk = (results['predictions']['ml_score'] > 70).sum()
                st.metric("ğŸš¨ Ø­Ø§Ù„Ø§Øª Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ±Ø©", high_risk)
                st.markdown("</div>", unsafe_allow_html=True)
            
            # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
            st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
            st.plotly_chart(automl.get_feature_importance_plot(results['feature_importance']), use_container_width=True)
            st.markdown("</div>", unsafe_allow_html=True)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù…Ø¹ Ø§Ù„ØªØµÙ†ÙŠÙ
            st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
            st.markdown("### ğŸ¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ (Ø¯Ø±Ø¬Ø© Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡)")
            
            display_cols = ['ml_score'] + automl.features[:5] + [automl.target]
            df_display = results['predictions'][display_cols].sort_values('ml_score', ascending=False)
            
            # ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
            def color_score(val):
                if val > 70:
                    return 'background-color: #ff4b4b; color: white;'
                elif val > 40:
                    return 'background-color: #ffa500; color: black;'
                else:
                    return 'background-color: #00f2fe; color: black;'
            
            styled_df = df_display.style.map(color_score, subset=['ml_score'])
            st.dataframe(styled_df, use_container_width=True)
            st.markdown("</div>", unsafe_allow_html=True)
            
            # ØªØ­Ù„ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ: ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
            st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
            fig = px.histogram(df_display, x='ml_score', nbins=20, 
                              title='ØªÙˆØ²ÙŠØ¹ Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø§Ø´ØªØ¨Ø§Ù‡',
                              color_discrete_sequence=['#ff4b4b'])
            fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', 
                            paper_bgcolor='rgba(0,0,0,0)',
                            font=dict(color='white'))
            st.plotly_chart(fig, use_container_width=True)
            st.markdown("</div>", unsafe_allow_html=True)
            
        else:
            st.error(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {error}")
    
    # Ø®Ø·ÙˆØ© 4: ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    status_text.text("ğŸ“¥ ØªØ¬Ù‡ÙŠØ² Ø§Ù„ØªØµØ¯ÙŠØ±...")
    progress_bar.progress(90)
    
    st.markdown("<div class='glass-card'>", unsafe_allow_html=True)
    st.markdown("### ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¸ÙŠÙ"):
            csv = df_cleaned.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„",
                data=csv,
                file_name=f'cleaned_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv'
            )
    
    with col2:
        if auto_train and results:
            if st.button("ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ"):
                csv = results['predictions'].to_csv(index=False).encode('utf-8-sig')
                st.download_button(
                    label="Ø§Ø¶ØºØ· Ù„Ù„ØªØ­Ù…ÙŠÙ„",
                    data=csv,
                    file_name=f'classified_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                    mime='text/csv'
                )
    st.markdown("</div>", unsafe_allow_html=True)
    
    # Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©
    progress_bar.progress(100)
    status_text.text("âœ… ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­!")
    
    # Ø±Ø³Ø§Ù„Ø© Ù†Ø¬Ø§Ø­ Ù…Ø¹ ØªØ£Ø«ÙŠØ±
    st.balloons()

else:
    # Ø¹Ø±Ø¶ ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø¨Ø¯Ø¡
    st.markdown("<div class='glass-card' style='text-align:center; padding:50px;'>", unsafe_allow_html=True)
    st.markdown("## ğŸ‘ˆ Ø§Ø¨Ø¯Ø£ Ø¨Ø±ÙØ¹ Ù…Ù„Ù CSV Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©")
    st.markdown("### Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±")
    st.markdown("---")
    
    if lottie_clean:
        st_lottie(lottie_clean, height=200, key="clean_anim")
    
    st.markdown("""
    ### ğŸš€ Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:
    - **ğŸ§¹ ØªÙ†Ø¸ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ**: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§ØªØŒ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©ØŒ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°
    - **ğŸ¤– ØªØ¹Ù„Ù… ØªÙ„Ù‚Ø§Ø¦ÙŠ**: ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ XGBoost Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø·
    - **ğŸ“Š ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…**: Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ©ØŒ ØªØ­Ù„ÙŠÙ„ Ø´Ø¨ÙƒØ§ØªØŒ NLP
    - **ğŸ“¥ ØªØµØ¯ÙŠØ± Ø§Ù„Ù†ØªØ§Ø¦Ø¬**: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„ØªØµÙ†ÙŠÙ
    """)
    st.markdown("</div>", unsafe_allow_html=True)

# -------------------------------
# 7. ÙÙˆØªØ±
# -------------------------------
st.markdown("---")
st.markdown("""
<div style='text-align:center; color:#8892b0; padding:20px;'>
    <p>Ø§Ù„Ø±Ù‚ÙŠØ¨ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ø°ÙƒÙŠ - AutoML | Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø© Â© 2025</p>
    <p style='font-size:12px;'>ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit, XGBoost, Scikit-learn</p>
</div>
""", unsafe_allow_html=True)
