# -*- coding: utf-8 -*-
"""
===========================================================================
ğŸ›¡ï¸ AI ADMINISTRATIVE AUDIT & JUDICIAL CORRUPTION DETECTION SYSTEM
===========================================================================
Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©ØŒ ÙƒØ´Ù Ø§Ù„ÙØ³Ø§Ø¯ ÙˆØ§Ù„Ø±Ø´ÙˆØ©ØŒ 
ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙØ³ÙŠØ±

Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 2.0 (Ultimate Edition)
Ø§Ù„Ù…Ø·ÙˆØ±: Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø±Ù‚Ø§Ø¨Ø© Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±ÙŠØ©
===========================================================================
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import warnings
import os
import re
import io
import base64
from datetime import datetime
import time
from collections import Counter
import hashlib
import json

warnings.filterwarnings('ignore')

# ==================== Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ ====================
from sklearn.ensemble import IsolationForest, RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, confusion_matrix, classification_report,
                             roc_curve, auc, roc_auc_score)
from sklearn.cluster import DBSCAN, KMeans
from sklearn.decomposition import PCA
from sklearn.neighbors import LocalOutlierFactor
from sklearn.covariance import EllipticEnvelope
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer

# XGBoost Ù„Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
try:
    from xgboost import XGBClassifier, XGBRegressor
    XGB_AVAILABLE = True
except:
    XGB_AVAILABLE = False

# transformers Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ØµÙˆØµ
try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except:
    TRANSFORMERS_AVAILABLE = False

# SHAP Ù„ØªÙØ³ÙŠØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
try:
    import shap
    SHAP_AVAILABLE = True
except:
    SHAP_AVAILABLE = False

# ==================== Ù…ÙƒØªØ¨Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ====================
try:
    from wordcloud import WordCloud, STOPWORDS
    import arabic_reshaper
    from bidi.algorithm import get_display
    import PyPDF2
    from textblob import TextBlob
    TEXT_ANALYSIS_AVAILABLE = True
except:
    TEXT_ANALYSIS_AVAILABLE = False

# ==================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ====================
st.set_page_config(
    page_title="AI Judicial & Administrative Audit",
    page_icon="âš–ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': 'https://www.ai-audit-system.com',
        'Report a bug': "https://github.com/ai-audit/issues",
        'About': "# AI Judicial Audit System\nØ§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ 2.0"
    }
)

# ==================== CSS Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…ØªØ·ÙˆØ± ====================
PROFESSIONAL_CSS = """
<style>
    @import url('https://fonts.googleapis.com/css2?family=Cairo:wght@300;400;600;700;900&display=swap');
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&display=swap');
    
    /* Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ§Øª */
    * {
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    
    /* Ø®Ù„ÙÙŠØ© Ø¯Ø§ÙƒÙ†Ø© Ù…ØªØ¯Ø±Ø¬Ø© */
    .stApp {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        font-family: 'Inter', 'Cairo', sans-serif;
    }
    
    /* Ù‡ÙŠØ¯Ø± Ø±Ø¦ÙŠØ³ÙŠ Ø¨ØªØ£Ø«ÙŠØ± Ø²Ø¬Ø§Ø¬ÙŠ */
    .main-header {
        background: rgba(255, 255, 255, 0.03);
        backdrop-filter: blur(20px);
        -webkit-backdrop-filter: blur(20px);
        border: 1px solid rgba(255, 255, 255, 0.05);
        border-radius: 0 0 40px 40px;
        padding: 3rem 2rem;
        margin-bottom: 3rem;
        text-align: center;
        position: relative;
        overflow: hidden;
        box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
    }
    
    .main-header::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(0, 255, 136, 0.1) 0%, transparent 70%);
        animation: rotate 30s linear infinite;
        z-index: 0;
    }
    
    @keyframes rotate {
        from { transform: rotate(0deg); }
        to { transform: rotate(360deg); }
    }
    
    .main-header h1 {
        font-size: 4rem;
        font-weight: 900;
        background: linear-gradient(135deg, #00ff88 0%, #00cc88 50%, #ffffff 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1rem;
        position: relative;
        z-index: 1;
        text-shadow: 0 0 30px rgba(0, 255, 136, 0.3);
        animation: glow 3s ease-in-out infinite;
    }
    
    @keyframes glow {
        0%, 100% { text-shadow: 0 0 30px rgba(0, 255, 136, 0.3); }
        50% { text-shadow: 0 0 50px rgba(0, 255, 136, 0.6); }
    }
    
    .main-header p {
        font-size: 1.3rem;
        color: rgba(255, 255, 255, 0.8);
        max-width: 800px;
        margin: 0 auto;
        position: relative;
        z-index: 1;
    }
    
    /* ÙƒØ±ÙˆØª Ø²Ø¬Ø§Ø¬ÙŠØ© Ù…ØªØ·ÙˆØ±Ø© */
    .glass-card {
        background: rgba(255, 255, 255, 0.02);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.05);
        border-radius: 24px;
        padding: 1.8rem;
        margin-bottom: 1.5rem;
        transition: all 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        position: relative;
        overflow: hidden;
    }
    
    .glass-card::after {
        content: '';
        position: absolute;
        top: 0;
        left: -100%;
        width: 100%;
        height: 100%;
        background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.02), transparent);
        transition: left 0.8s;
    }
    
    .glass-card:hover::after {
        left: 100%;
    }
    
    .glass-card:hover {
        transform: translateY(-8px) scale(1.02);
        border-color: rgba(0, 255, 136, 0.3);
        box-shadow: 0 20px 40px rgba(0, 255, 136, 0.1);
    }
    
    .card-title {
        font-size: 1.5rem;
        font-weight: 700;
        background: linear-gradient(135deg, #ffffff 0%, #00ff88 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin-bottom: 1.2rem;
        border-bottom: 1px solid rgba(0, 255, 136, 0.2);
        padding-bottom: 0.8rem;
        display: flex;
        align-items: center;
        gap: 0.5rem;
    }
    
    /* Ù…Ù‚Ø§ÙŠÙŠØ³ Ù†ÙŠÙˆÙ† Ù…ØªØ£Ù„Ù‚Ø© */
    .metric-neon {
        background: linear-gradient(135deg, rgba(0, 255, 136, 0.1) 0%, rgba(0, 200, 100, 0.05) 100%);
        border: 1px solid rgba(0, 255, 136, 0.2);
        border-radius: 20px;
        padding: 1.8rem;
        text-align: center;
        transition: all 0.3s;
        position: relative;
        overflow: hidden;
    }
    
    .metric-neon::before {
        content: '';
        position: absolute;
        top: -2px;
        left: -2px;
        right: -2px;
        bottom: -2px;
        background: linear-gradient(45deg, #00ff88, transparent, #00ff88);
        border-radius: 22px;
        z-index: -1;
        animation: borderGlow 3s linear infinite;
        opacity: 0;
        transition: opacity 0.3s;
    }
    
    .metric-neon:hover::before {
        opacity: 1;
    }
    
    @keyframes borderGlow {
        0% { transform: rotate(0deg); }
        100% { transform: rotate(360deg); }
    }
    
    .metric-neon:hover {
        transform: scale(1.05);
        border-color: #00ff88;
    }
    
    .metric-neon-value {
        font-size: 3rem;
        font-weight: 900;
        color: #00ff88;
        text-shadow: 0 0 20px rgba(0, 255, 136, 0.5);
        line-height: 1.2;
    }
    
    .metric-neon-label {
        font-size: 1rem;
        color: rgba(255, 255, 255, 0.7);
        text-transform: uppercase;
        letter-spacing: 2px;
        margin-top: 0.5rem;
    }
    
    /* Ø´Ø§Ø±Ø§Øª Ù…ØªØ®ØµØµØ© */
    .badge {
        display: inline-block;
        padding: 0.5rem 1.2rem;
        border-radius: 50px;
        font-weight: 600;
        font-size: 0.9rem;
        letter-spacing: 1px;
        margin: 0.3rem;
        transition: all 0.3s;
    }
    
    .badge:hover {
        transform: translateY(-2px);
        filter: brightness(1.2);
    }
    
    .badge-primary {
        background: linear-gradient(135deg, #00ff88, #00cc88);
        color: #0f172a;
        box-shadow: 0 5px 15px rgba(0, 255, 136, 0.3);
    }
    
    .badge-danger {
        background: linear-gradient(135deg, #ff4b4b, #dc2626);
        color: white;
        box-shadow: 0 5px 15px rgba(255, 75, 75, 0.3);
    }
    
    .badge-warning {
        background: linear-gradient(135deg, #fbbf24, #d97706);
        color: #0f172a;
        box-shadow: 0 5px 15px rgba(251, 191, 36, 0.3);
    }
    
    .badge-info {
        background: linear-gradient(135deg, #3b82f6, #1d4ed8);
        color: white;
        box-shadow: 0 5px 15px rgba(59, 130, 246, 0.3);
    }
    
    /* Ø£Ø²Ø±Ø§Ø± Ù†ÙŠÙˆÙ† Ù…ØªØ·ÙˆØ±Ø© */
    .stButton > button {
        background: linear-gradient(135deg, #00ff88 0%, #00cc88 100%);
        color: #0f172a;
        border: none;
        border-radius: 14px;
        padding: 0.8rem 2rem;
        font-weight: 700;
        font-size: 1rem;
        text-transform: uppercase;
        letter-spacing: 1.5px;
        transition: all 0.3s;
        box-shadow: 0 8px 20px rgba(0, 255, 136, 0.3);
        position: relative;
        overflow: hidden;
        width: 100%;
    }
    
    .stButton > button::after {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: linear-gradient(45deg, transparent, rgba(255, 255, 255, 0.3), transparent);
        transform: rotate(45deg);
        animation: buttonShine 3s infinite;
    }
    
    @keyframes buttonShine {
        0% { transform: translateX(-100%) rotate(45deg); }
        100% { transform: translateX(100%) rotate(45deg); }
    }
    
    .stButton > button:hover {
        transform: scale(1.05);
        box-shadow: 0 15px 30px rgba(0, 255, 136, 0.5);
    }
    
    /* ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù…ØªØ·ÙˆØ±Ø© */
    .stTabs [data-baseweb="tab-list"] {
        gap: 0.8rem;
        background: rgba(255, 255, 255, 0.03);
        padding: 0.5rem;
        border-radius: 60px;
        backdrop-filter: blur(10px);
        border: 1px solid rgba(255, 255, 255, 0.05);
        margin-bottom: 2rem;
    }
    
    .stTabs [data-baseweb="tab"] {
        background: transparent;
        border-radius: 50px;
        padding: 0.8rem 2rem;
        font-weight: 600;
        color: rgba(255, 255, 255, 0.6);
        border: none;
        transition: all 0.3s;
        font-size: 1rem;
    }
    
    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, #00ff88, #00cc88) !important;
        color: #0f172a !important;
        box-shadow: 0 8px 20px rgba(0, 255, 136, 0.4);
        font-weight: 700;
    }
    
    /* Ø´Ø±ÙŠØ· Ø¬Ø§Ù†Ø¨ÙŠ Ù…ØªØ·ÙˆØ± */
    .css-1d391kg {
        background: linear-gradient(180deg, #1e293b 0%, #0f172a 100%);
        border-right: 1px solid rgba(255, 255, 255, 0.05);
    }
    
    .sidebar-content {
        padding: 2rem 1rem;
    }
    
    /* Ø´Ø±ÙŠØ· Ø§Ù„ØªÙ‚Ø¯Ù… */
    .progress-container {
        width: 100%;
        height: 8px;
        background: rgba(255, 255, 255, 0.1);
        border-radius: 4px;
        margin: 1rem 0;
        overflow: hidden;
    }
    
    .progress-bar {
        height: 100%;
        background: linear-gradient(90deg, #00ff88, #00cc88);
        border-radius: 4px;
        transition: width 0.5s ease;
    }
    
    /* ØªØ°ÙŠÙŠÙ„ Ø§Ø­ØªØ±Ø§ÙÙŠ */
    .footer {
        background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%);
        border-top: 1px solid rgba(0, 255, 136, 0.2);
        padding: 3rem 2rem;
        margin-top: 4rem;
        text-align: center;
        border-radius: 40px 40px 0 0;
        position: relative;
        overflow: hidden;
    }
    
    .footer::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        right: 0;
        height: 2px;
        background: linear-gradient(90deg, transparent, #00ff88, transparent);
    }
    
    .footer h3 {
        color: white;
        font-size: 2rem;
        margin-bottom: 1rem;
        background: linear-gradient(135deg, #00ff88, #ffffff);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .footer p {
        color: rgba(255, 255, 255, 0.6);
        font-size: 1rem;
    }
    
    /* Ø£Ù†ÙŠÙ…ÙŠØ´Ù† Ù„Ù„Ø¹Ù†Ø§ØµØ± */
    @keyframes float {
        0% { transform: translateY(0px); }
        50% { transform: translateY(-10px); }
        100% { transform: translateY(0px); }
    }
    
    .float-animation {
        animation: float 4s ease-in-out infinite;
    }
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ */
    .dataframe {
        background: rgba(255, 255, 255, 0.02);
        border-radius: 16px;
        border: 1px solid rgba(255, 255, 255, 0.05);
    }
    
    .dataframe th {
        background: rgba(0, 255, 136, 0.1);
        color: #00ff88;
        font-weight: 600;
        padding: 1rem;
    }
    
    .dataframe td {
        color: rgba(255, 255, 255, 0.8);
        padding: 0.8rem 1rem;
        border-bottom: 1px solid rgba(255, 255, 255, 0.05);
    }
    
    /* ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª */
    .alert {
        padding: 1.2rem;
        border-radius: 16px;
        margin: 1rem 0;
        border: 1px solid;
        backdrop-filter: blur(10px);
    }
    
    .alert-success {
        background: rgba(0, 255, 136, 0.1);
        border-color: rgba(0, 255, 136, 0.3);
        color: #00ff88;
    }
    
    .alert-warning {
        background: rgba(251, 191, 36, 0.1);
        border-color: rgba(251, 191, 36, 0.3);
        color: #fbbf24;
    }
    
    .alert-danger {
        background: rgba(255, 75, 75, 0.1);
        border-color: rgba(255, 75, 75, 0.3);
        color: #ff4b4b;
    }
    
    .alert-info {
        background: rgba(59, 130, 246, 0.1);
        border-color: rgba(59, 130, 246, 0.3);
        color: #3b82f6;
    }
    
    /* ØªØ­Ø³ÙŠÙ† Ø¸Ù‡ÙˆØ± Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© */
    .arabic-text {
        direction: rtl;
        font-family: 'Cairo', sans-serif;
    }
</style>
"""

# ==================== ØªØ·Ø¨ÙŠÙ‚ CSS ====================
st.markdown(PROFESSIONAL_CSS, unsafe_allow_html=True)

# ==================== ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© ====================
def init_session_state():
    """ØªÙ‡ÙŠØ¦Ø© Ø¬Ù…ÙŠØ¹ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø©"""
    defaults = {
        'data_loaded': False,
        'justice_df': None,
        'database_df': None,
        'merged_df': None,
        'model_trained': False,
        'anomalies': None,
        'model_pack': None,
        'bias_report': None,
        'predictions': None,
        'shap_values': None,
        'legal_texts': [],
        'analysis_history': [],
        'theme': 'dark',
        'processing_time': 0,
        'file_info': {},
        'corruption_cases': [],
        'nlp_model': None
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

init_session_state()

# ==================== ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ NLP ====================
@st.cache_resource
def load_nlp_model():
    """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ"""
    if TRANSFORMERS_AVAILABLE:
        try:
            return pipeline("zero-shot-classification", model="facebook/bart-large-mnli")
        except:
            return None
    return None

# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© ====================

def load_justice_data(justice_file, database_file):
    """ØªØ­Ù…ÙŠÙ„ ÙˆØ¯Ù…Ø¬ Ù…Ù„ÙØ§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¡"""
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
    df_justice = pd.read_csv(justice_file)
    df_database = pd.read_csv(database_file)
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù„ÙØ§Øª
    merged_df = pd.merge(df_justice, df_database, on='docket', how='inner')
    
    return df_justice, df_database, merged_df

def detect_data_quality(df):
    """ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª"""
    report = {
        'total_rows': len(df),
        'total_columns': len(df.columns),
        'missing_values': df.isnull().sum().sum(),
        'duplicates': df.duplicated().sum(),
        'memory_usage': df.memory_usage(deep=True).sum() / 1024**2,  # MB
        'data_types': df.dtypes.value_counts().to_dict(),
        'numeric_columns': len(df.select_dtypes(include=[np.number]).columns),
        'categorical_columns': len(df.select_dtypes(include=['object']).columns),
        'columns_info': {}
    }
    
    # ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ø¹Ù…ÙˆØ¯
    for col in df.columns:
        col_info = {
            'type': str(df[col].dtype),
            'missing': df[col].isnull().sum(),
            'missing_pct': (df[col].isnull().sum() / len(df)) * 100,
            'unique': df[col].nunique()
        }
        
        if df[col].dtype in ['int64', 'float64']:
            col_info.update({
                'min': float(df[col].min()) if not pd.isna(df[col].min()) else None,
                'max': float(df[col].max()) if not pd.isna(df[col].max()) else None,
                'mean': float(df[col].mean()) if not pd.isna(df[col].mean()) else None,
                'std': float(df[col].std()) if not pd.isna(df[col].std()) else None,
                'skew': float(df[col].skew()) if not pd.isna(df[col].skew()) else None
            })
        
        report['columns_info'][col] = col_info
    
    return report

def clean_dataframe(df):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ø°ÙƒÙŠ"""
    df_clean = df.copy()
    
    # 1. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØµÙÙˆÙ Ø§Ù„Ù…ÙƒØ±Ø±Ø©
    initial_len = len(df_clean)
    df_clean.drop_duplicates(inplace=True)
    
    # 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    for col in df_clean.columns:
        if df_clean[col].dtype in ['int64', 'float64']:
            # Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©: ØªØ¹Ø¨Ø¦Ø© Ø¨Ø§Ù„ÙˆØ³ÙŠØ·
            df_clean[col].fillna(df_clean[col].median(), inplace=True)
        else:
            # Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†ØµÙŠØ©: ØªØ¹Ø¨Ø¦Ø© Ø¨Ø§Ù„Ù‚ÙŠÙ…Ø© Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹
            df_clean[col].fillna(df_clean[col].mode()[0] if not df_clean[col].mode().empty else 'Unknown', inplace=True)
    
    # 3. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªØ·Ø±ÙØ© (Ù„Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ©)
    numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 3 * IQR
        upper_bound = Q3 + 3 * IQR
        df_clean[col] = df_clean[col].clip(lower_bound, upper_bound)
    
    removed_rows = initial_len - len(df_clean)
    
    return df_clean, removed_rows

def extract_text_from_pdf(pdf_file):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ù…Ù„Ù PDF"""
    if not TEXT_ANALYSIS_AVAILABLE:
        return ["Ù…ÙƒØªØ¨Ø§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©"]
    
    try:
        pdf_reader = PyPDF2.PdfReader(pdf_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        return text.split('\n')
    except Exception as e:
        return [f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© PDF: {str(e)}"]

# ==================== Ø¯ÙˆØ§Ù„ ÙƒØ´Ù Ø§Ù„ÙØ³Ø§Ø¯ ÙˆØ§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ ====================

def calculate_judicial_risk(facts, verdict, crime_type, model=None):
    """Ø­Ø³Ø§Ø¨ Ù…Ø®Ø§Ø·Ø±Ø© Ø§Ù„Ø±Ø´ÙˆØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ ÙˆØ§Ù„ÙˆØ§Ù‚Ø¹"""
    risk_score = 0
    
    # Ù…Ø¹ÙŠØ§Ø± 1: ØªÙ†Ø§Ù‚Ø¶ Ø§Ù„Ø¬Ø±ÙŠÙ…Ø© Ø§Ù„Ø®Ø·ÙŠØ±Ø© Ù…Ø¹ Ø§Ù„Ø­ÙƒÙ… Ø§Ù„Ù…Ø®ÙÙ
    if crime_type in ['Drug Law', 'Criminal Organization', 'Terrorism', 'Money Laundering'] and verdict == 'In Favor':
        risk_score += 40
    
    # Ù…Ø¹ÙŠØ§Ø± 2: Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ NLP Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
    if model is not None and facts and len(str(facts)) > 10:
        try:
            labels = ["guilty", "innocent", "liable", "not liable"]
            result = model(str(facts)[:1000], candidate_labels=labels)
            top_prediction = result['labels'][0]
            confidence = result['scores'][0]
            
            # ØªÙ†Ø§Ù‚Ø¶ Ø¨ÙŠÙ† ØªÙˆÙ‚Ø¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„Ø­ÙƒÙ… Ø§Ù„ÙØ¹Ù„ÙŠ
            if verdict == 'In Favor' and top_prediction in ["guilty", "liable"] and confidence > 0.7:
                risk_score += confidence * 50
        except:
            pass
    
    return risk_score

def detect_fraud_patterns_judicial(df):
    """ÙƒØ´Ù Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ³Ø§Ø¯ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©"""
    fraud_report = {
        'total_cases': len(df),
        'suspicious_cases': 0,
        'fraud_indicators': [],
        'high_risk_cases': [],
        'corruption_score': 0,
        'patterns': []
    }
    
    indicators = []
    
    # 1. ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØµÙˆÙŠØª (Ø§Ù„Ù‚Ø¶Ø§Ø©)
    if 'majority_votes' in df.columns and 'minority_votes' in df.columns:
        # Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªØµÙˆÙŠØª Ø§Ù„Ù…Ù†Ù‚Ø³Ù… Ø¨Ø´Ø¯Ø©
        df['vote_ratio'] = df['majority_votes'] / (df['minority_votes'] + 1)
        extreme_division = df[df['vote_ratio'] < 1.5]
        if len(extreme_division) > 0:
            indicators.append({
                'type': 'extreme_division',
                'count': len(extreme_division),
                'description': 'Ù‚Ø¶Ø§ÙŠØ§ Ø¨ØªØµÙˆÙŠØª Ù…Ù†Ù‚Ø³Ù… Ø¨Ø´Ø¯Ø©'
            })
    
    # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø¯Ø© Ø§Ù„Ø²Ù…Ù†ÙŠØ©
    if 'duration_days' in df.columns:
        mean_duration = df['duration_days'].mean()
        std_duration = df['duration_days'].std()
        very_short = df[df['duration_days'] < mean_duration - 2*std_duration]
        very_long = df[df['duration_days'] > mean_duration + 2*std_duration]
        
        if len(very_short) > 0:
            indicators.append({
                'type': 'very_short',
                'count': len(very_short),
                'description': 'Ù‚Ø¶Ø§ÙŠØ§ Ø¨Ù…Ø¯Ø© Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹ (Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹)'
            })
        if len(very_long) > 0:
            indicators.append({
                'type': 'very_long',
                'count': len(very_long),
                'description': 'Ù‚Ø¶Ø§ÙŠØ§ Ø¨Ù…Ø¯Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ (Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„Ù…ØªÙˆÙ‚Ø¹)'
            })
    
    # 3. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ù…Ø¹ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ†
    if 'lawyer' in df.columns and 'first_party_winner' in df.columns:
        lawyer_win_rate = df.groupby('lawyer')['first_party_winner'].mean()
        suspicious_lawyers = lawyer_win_rate[lawyer_win_rate > 0.8]
        if len(suspicious_lawyers) > 0:
            indicators.append({
                'type': 'suspicious_lawyers',
                'count': len(suspicious_lawyers),
                'description': 'Ù…Ø­Ø§Ù…ÙˆÙ† Ø¨Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ø§Ù‹ (>80%)'
            })
    
    fraud_report['fraud_indicators'] = indicators
    fraud_report['suspicious_cases'] = sum(ind.get('count', 0) for ind in indicators)
    fraud_report['corruption_score'] = min(fraud_report['suspicious_cases'] / len(df) * 100, 100)
    
    return fraud_report

def detect_anomalies_advanced(df, contamination=0.1):
    """ÙƒØ´Ù Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ø´Ø°ÙˆØ° Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø©"""
    
    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ©
    numeric_df = df.select_dtypes(include=[np.number]).fillna(0)
    
    if len(numeric_df.columns) == 0:
        return None, None
    
    # ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
    scaler = RobustScaler()
    X_scaled = scaler.fit_transform(numeric_df)
    
    # 1. Isolation Forest
    iso_forest = IsolationForest(
        contamination=contamination,
        random_state=42,
        n_estimators=100
    )
    iso_pred = iso_forest.fit_predict(X_scaled)
    
    # 2. Local Outlier Factor
    lof = LocalOutlierFactor(
        contamination=contamination,
        n_neighbors=20
    )
    lof_pred = lof.fit_predict(X_scaled)
    
    # 3. DBSCAN
    dbscan = DBSCAN(eps=0.5, min_samples=5)
    dbscan_pred = dbscan.fit_predict(X_scaled)
    dbscan_outliers = (dbscan_pred == -1).astype(int)
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø§Ù„ØªØµÙˆÙŠØª)
    ensemble_score = (iso_pred + lof_pred + dbscan_outliers) / 3
    ensemble_score = (ensemble_score + 1) / 2  # ØªØ·Ø¨ÙŠØ¹ Ø¥Ù„Ù‰ [0, 1]
    
    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ø¨Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    results = df.copy()
    results['anomaly_score_iso'] = (iso_pred == -1).astype(int)
    results['anomaly_score_lof'] = (lof_pred == -1).astype(int)
    results['anomaly_score_dbscan'] = dbscan_outliers
    results['anomaly_score_ensemble'] = ensemble_score
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø´Ø§Ø° Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø¯Ø±Ø¬Ø§Øª
    results['is_anomaly'] = results[['anomaly_score_iso', 'anomaly_score_lof', 'anomaly_score_dbscan']].mean(axis=1) > 0.5
    
    return results, numeric_df.columns.tolist()

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯ ====================

def train_corruption_model(df, target_col=None):
    """ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯"""
    
    if target_col is None:
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¹Ù…ÙˆØ¯ Ù…Ù†Ø§Ø³Ø¨ ÙƒÙ‡Ø¯Ù
        possible_targets = ['fraud', 'corruption', 'churn', 'default', 'risk', 'label', 'class', 'first_party_winner']
        for col in df.columns:
            if any(target in col.lower() for target in possible_targets):
                target_col = col
                break
    
    if target_col is None:
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù‡Ø¯ÙØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù†ØªØ§Ø¦Ø¬ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° ÙƒÙ‡Ø¯Ù
        return None, "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ Ù‡Ø¯Ù Ù„Ù„ØªØ¯Ø±ÙŠØ¨"
    
    # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…ÙŠØ²Ø§Øª
    feature_cols = [col for col in df.columns if col != target_col and df[col].dtype in ['int64', 'float64']]
    
    if len(feature_cols) == 0:
        return None, "Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ÙŠØ²Ø§Øª Ø±Ù‚Ù…ÙŠØ© ÙƒØ§ÙÙŠØ©"
    
    X = df[feature_cols].fillna(0)
    y = df[target_col]
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‡Ø¯Ù Ø¥Ù„Ù‰ Ù‚ÙŠÙ… Ø«Ù†Ø§Ø¦ÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ØµÙŠØ§Ù‹
    if y.dtype == 'object':
        y = (y == y.mode()[0]).astype(int)
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y)) > 1 else None
    )
    
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    if XGB_AVAILABLE:
        model = XGBClassifier(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1,
            random_state=42,
            use_label_encoder=False,
            eval_metric='logloss'
        )
    else:
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=5,
            random_state=42
        )
    
    model.fit(X_train, y_train)
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    y_pred = model.predict(X_test)
    
    metrics = {
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),
        'recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),
        'f1': f1_score(y_test, y_pred, average='weighted', zero_division=0)
    }
    
    # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
    feature_importance = pd.DataFrame({
        'feature': feature_cols,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    result = {
        'model': model,
        'metrics': metrics,
        'feature_importance': feature_importance,
        'feature_cols': feature_cols,
        'target_col': target_col,
        'X_test': X_test,
        'y_test': y_test,
        'y_pred': y_pred
    }
    
    return result, None

# ==================== Ø¯ÙˆØ§Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ====================

def analyze_legal_text(texts):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
    
    if not TEXT_ANALYSIS_AVAILABLE or not texts:
        return {"error": "Ù…ÙƒØªØ¨Ø§Øª ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ØºÙŠØ± Ù…ØªÙˆÙØ±Ø©"}
    
    results = {}
    
    # Ø¯Ù…Ø¬ Ø§Ù„Ù†ØµÙˆØµ
    full_text = ' '.join(texts)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
    full_text = re.sub(r'[^\w\s]', '', full_text)
    full_text = re.sub(r'\d+', '', full_text)
    
    # ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    arabic_stopwords = set(['ÙÙŠ', 'Ù…Ù†', 'Ø¥Ù„Ù‰', 'Ø¹Ù„Ù‰', 'ÙƒØ§Ù†', 'Ù‡Ø°Ø§', 'Ø£Ù†', 
                            'Ù‚Ø¯', 'Ù„Ø§', 'Ù…Ø§', 'Ù‡Ù„', 'Ù„Ù…', 'Ù„Ù‚Ø¯', 'Ø¥Ù†',
                            'Ø¹Ù†Ø¯', 'Ù…Ø¹', 'Ù‡Ø°Ù‡', 'Ø°Ù„Ùƒ', 'ÙŠÙ…ÙƒÙ†', 'Ø³ÙˆÙ'])
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª
    words = [w for w in full_text.split() if len(w) > 2 and w not in arabic_stopwords]
    word_counts = Counter(words).most_common(30)
    results['top_words'] = word_counts
    
    # Ø¥Ù†Ø´Ø§Ø¡ Word Cloud
    try:
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ÙƒÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ
        reshaped_text = arabic_reshaper.reshape(full_text)
        bidi_text = get_display(reshaped_text)
        
        wordcloud = WordCloud(
            width=1000,
            height=500,
            background_color='black',
            colormap='Greens',
            max_words=100,
            random_state=42
        ).generate(bidi_text)
        
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        ax.set_title('Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹ ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©', color='white', fontsize=16)
        plt.tight_layout()
        
        results['wordcloud'] = fig
    except Exception as e:
        results['wordcloud_error'] = str(e)
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø±
    try:
        blob = TextBlob(full_text)
        results['sentiment'] = {
            'polarity': blob.sentiment.polarity,
            'subjectivity': blob.sentiment.subjectivity
        }
    except:
        pass
    
    return results

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„ØªØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ====================

def create_correlation_heatmap(df):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ© Ù„Ù„Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª"""
    numeric_df = df.select_dtypes(include=[np.number])
    if len(numeric_df.columns) < 2:
        return None
    
    corr_matrix = numeric_df.corr()
    
    fig = go.Figure(data=go.Heatmap(
        z=corr_matrix.values,
        x=corr_matrix.columns,
        y=corr_matrix.columns,
        colorscale='Viridis',
        zmin=-1, zmax=1,
        text=np.round(corr_matrix.values, 2),
        texttemplate='%{text}',
        textfont={"size": 10},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title='Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª',
        height=600,
        width=800,
        xaxis_title='Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª',
        yaxis_title='Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª'
    )
    
    return fig

def create_anomaly_dashboard(anomaly_df, original_df):
    """Ø¥Ù†Ø´Ø§Ø¡ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Ù…ØªÙƒØ§Ù…Ù„Ø© Ù„Ù„Ø´Ø°ÙˆØ°"""
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø´Ø°ÙˆØ°', 'Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø´Ø°ÙˆØ°', 'Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©', 'ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª'),
        specs=[[{'type': 'pie'}, {'type': 'bar'}],
               [{'type': 'scatter'}, {'type': 'heatmap'}]]
    )
    
    # 1. ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø´Ø°ÙˆØ°
    anomaly_counts = anomaly_df['is_anomaly'].value_counts()
    fig.add_trace(
        go.Pie(
            labels=['Ø·Ø¨ÙŠØ¹ÙŠ', 'Ø´Ø§Ø°'],
            values=[anomaly_counts.get(False, 0), anomaly_counts.get(True, 0)],
            marker=dict(colors=['#00ff88', '#ff4b4b']),
            textinfo='label+percent'
        ),
        row=1, col=1
    )
    
    # 2. Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø´Ø°ÙˆØ°
    fig.add_trace(
        go.Bar(
            x=anomaly_df.index[:30],
            y=anomaly_df['anomaly_score_ensemble'][:30],
            marker_color=anomaly_df['anomaly_score_ensemble'][:30],
            marker_colorscale='RdYlGn_r',
            name='Ø¯Ø±Ø¬Ø§Øª Ø§Ù„Ø´Ø°ÙˆØ°'
        ),
        row=1, col=2
    )
    
    # 3. Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©
    if 'majority_votes' in anomaly_df.columns:
        fig.add_trace(
            go.Scatter(
                x=anomaly_df.index[:50],
                y=anomaly_df['majority_votes'][:50],
                mode='markers',
                marker=dict(
                    size=anomaly_df['anomaly_score_ensemble'][:50] * 20,
                    color=anomaly_df['is_anomaly'][:50],
                    colorscale=[[0, '#00ff88'], [1, '#ff4b4b']],
                    showscale=True
                ),
                name='Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§'
            ),
            row=2, col=1
        )
    
    fig.update_layout(
        height=800,
        showlegend=False,
        title_text="Ù„ÙˆØ­Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„Ø©",
        title_font_size=20
    )
    
    return fig

# ==================== Ø¯ÙˆØ§Ù„ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ====================

def display_header():
    """Ø¹Ø±Ø¶ Ø§Ù„Ù‡ÙŠØ¯Ø± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
    st.markdown("""
    <div class="main-header">
        <h1>âš–ï¸ AI JUDICIAL AUDIT SYSTEM</h1>
        <p>Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„ÙƒØ´Ù Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</p>
        <div style="margin-top: 2rem;">
            <span class="badge badge-primary">âœ¨ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ</span>
            <span class="badge badge-info">ğŸ” ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°</span>
            <span class="badge badge-warning">âš–ï¸ ØªØ­Ù„ÙŠÙ„ Ù‚Ø¶Ø§Ø¦ÙŠ</span>
            <span class="badge badge-danger">ğŸš« Ù…ÙƒØ§ÙØ­Ø© ÙØ³Ø§Ø¯</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

def display_metrics_card(title, value, subtitle, color='primary'):
    """Ø¹Ø±Ø¶ Ø¨Ø·Ø§Ù‚Ø© Ù…Ù‚Ø§ÙŠÙŠØ³"""
    color_class = f"badge-{color}"
    st.markdown(f"""
    <div class="metric-neon">
        <div class="metric-neon-value">{value}</div>
        <div class="metric-neon-label">{title}</div>
        <div style="margin-top: 0.5rem; font-size: 0.9rem; color: rgba(255,255,255,0.5);">{subtitle}</div>
    </div>
    """, unsafe_allow_html=True)

def display_alert(message, type='info'):
    """Ø¹Ø±Ø¶ ØªÙ†Ø¨ÙŠÙ‡"""
    alert_class = f"alert-{type}"
    st.markdown(f"""
    <div class="alert {alert_class}">
        {message}
    </div>
    """, unsafe_allow_html=True)

# ==================== Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ====================

def main():
    # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ NLP
    if st.session_state.nlp_model is None and TRANSFORMERS_AVAILABLE:
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ..."):
            st.session_state.nlp_model = load_nlp_model()
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù‡ÙŠØ¯Ø±
    display_header()
    
    # Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.markdown("""
        <div style="text-align: center; padding: 1rem;">
            <h2 style="color: #00ff88;">ğŸ”§ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©</h2>
        </div>
        """, unsafe_allow_html=True)
        
        # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª
        st.markdown("### ğŸ“ Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©")
        
        justice_file = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„Ù justice.csv",
            type=['csv'],
            key='justice_uploader'
        )
        
        database_file = st.file_uploader(
            "Ø±ÙØ¹ Ù…Ù„Ù database.csv",
            type=['csv'],
            key='database_uploader'
        )
        
        if justice_file is not None and database_file is not None:
            if st.button("ğŸš€ ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    try:
                        df_justice, df_database, merged_df = load_justice_data(justice_file, database_file)
                        
                        st.session_state.justice_df = df_justice
                        st.session_state.database_df = df_database
                        st.session_state.merged_df = merged_df
                        st.session_state.data_loaded = True
                        st.session_state.file_info = {
                            'justice_rows': len(df_justice),
                            'database_rows': len(df_database),
                            'merged_rows': len(merged_df),
                            'justice_cols': len(df_justice.columns),
                            'database_cols': len(df_database.columns)
                        }
                        
                        st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(df_justice)} Ù‚Ø¶ÙŠØ© ÙˆØ¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ {len(df_database)} Ø³Ø¬Ù„")
                    except Exception as e:
                        st.error(f"Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª: {str(e)}")
        
        # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
        legal_file = st.file_uploader(
            "Ø±ÙØ¹ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© (PDF, TXT)",
            type=['pdf', 'txt'],
            key='legal_uploader'
        )
        
        if legal_file is not None:
            if st.button("ğŸ“„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ..."):
                    if legal_file.name.endswith('.pdf'):
                        texts = extract_text_from_pdf(legal_file)
                    else:
                        texts = legal_file.getvalue().decode('utf-8').split('\n')
                    
                    st.session_state.legal_texts = texts
                    st.success(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ {len(texts)} Ø³Ø·Ø± Ù†ØµÙŠ")
        
        st.markdown("---")
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
        if st.session_state.data_loaded:
            st.markdown("### âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ")
            
            contamination = st.slider(
                "Ø­Ø³Ø§Ø³ÙŠØ© ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ°",
                min_value=0.01,
                max_value=0.3,
                value=0.05,
                step=0.01,
                help="Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© ÙƒØ´Ø§Ø°Ø©"
            )
            
            if st.button("ğŸ” ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    anomalies_df, features = detect_anomalies_advanced(
                        st.session_state.merged_df if st.session_state.merged_df is not None else st.session_state.justice_df,
                        contamination=contamination
                    )
                    
                    if anomalies_df is not None:
                        st.session_state.anomalies = anomalies_df
                        
                        # ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ
                        fraud_report = detect_fraud_patterns_judicial(anomalies_df)
                        st.session_state.fraud_report = fraud_report
                        
                        st.success(f"âœ… ØªÙ… Ø§ÙƒØªØ´Ø§Ù {anomalies_df['is_anomaly'].sum()} Ù‚Ø¶ÙŠØ© Ù…Ø´Ø¨ÙˆÙ‡Ø©")
            
            if st.button("ğŸ¤– ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬..."):
                    model_result, error = train_corruption_model(
                        st.session_state.merged_df if st.session_state.merged_df is not None else st.session_state.justice_df
                    )
                    
                    if model_result is not None:
                        st.session_state.model_pack = model_result
                        st.success(f"âœ… ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø©: {model_result['metrics']['accuracy']*100:.1f}%")
                    else:
                        st.warning(f"âš ï¸ {error}")
        
        st.markdown("---")
        
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
        if st.session_state.file_info:
            st.markdown("### ğŸ“Š Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            info = st.session_state.file_info
            st.markdown(f"""
            <div style="background: rgba(0,255,136,0.05); padding: 1rem; border-radius: 12px;">
                <p><strong>justice.csv:</strong> {info.get('justice_rows', 0):,} Ø³Ø¬Ù„</p>
                <p><strong>database.csv:</strong> {info.get('database_rows', 0):,} Ø³Ø¬Ù„</p>
                <p><strong>Ø¨Ø¹Ø¯ Ø§Ù„Ø¯Ù…Ø¬:</strong> {info.get('merged_rows', 0):,} Ø³Ø¬Ù„</p>
            </div>
            """, unsafe_allow_html=True)
    
    # Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    if not st.session_state.data_loaded and not st.session_state.legal_texts:
        # Ø´Ø§Ø´Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="glass-card float-animation">
                <div style="font-size: 3rem; text-align: center;">âš–ï¸</div>
                <h3 style="color: #00ff88; text-align: center;">ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§</h3>
                <p style="color: rgba(255,255,255,0.7); text-align: center;">Ø¯Ù…Ø¬ ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ù„ÙØ§Øª justice.csv Ùˆ database.csv</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="glass-card float-animation" style="animation-delay: 0.2s;">
                <div style="font-size: 3rem; text-align: center;">ğŸ”</div>
                <h3 style="color: #00ff88; text-align: center;">ÙƒØ´Ù Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ</h3>
                <p style="color: rgba(255,255,255,0.7); text-align: center;">Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ø¹Ø§Ø¯ÙŠØ© ÙˆØ´Ø¨Ù‡Ø§Øª Ø±Ø´ÙˆØ©</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="glass-card float-animation" style="animation-delay: 0.4s;">
                <div style="font-size: 3rem; text-align: center;">ğŸ“Š</div>
                <h3 style="color: #00ff88; text-align: center;">ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù…</h3>
                <p style="color: rgba(255,255,255,0.7); text-align: center;">ÙÙ‡Ù… Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª</p>
            </div>
            """, unsafe_allow_html=True)
        
        return
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØ¨ÙˆÙŠØ¨Ø§Øª
    tabs = st.tabs([
        "ğŸ“Š Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©",
        "ğŸ” ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ",
        "ğŸ¤– Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯",
        "âš–ï¸ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ",
        "ğŸ“ˆ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©"
    ])
    
    # ========== ØªØ¨ÙˆÙŠØ¨ Ù„ÙˆØ­Ø© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ==========
    with tabs[0]:
        if st.session_state.merged_df is not None:
            df = st.session_state.merged_df
            
            st.markdown('<div class="glass-card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ“Š Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©</div>', unsafe_allow_html=True)
            
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø³Ø±ÙŠØ¹Ø©
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                display_metrics_card(
                    "Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§",
                    f"{len(df):,}",
                    f"{len(df.columns)} Ø¹Ù…ÙˆØ¯"
                )
            
            with col2:
                if 'majority_votes' in df.columns:
                    avg_votes = df['majority_votes'].mean()
                    display_metrics_card(
                        "Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØµÙˆÙŠØª",
                        f"{avg_votes:.1f}",
                        "Ø£ØºÙ„Ø¨ÙŠØ© Ø§Ù„Ù‚Ø¶Ø§Ø©"
                    )
            
            with col3:
                if 'first_party_winner' in df.columns:
                    win_rate = df['first_party_winner'].mean() * 100
                    display_metrics_card(
                        "Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„",
                        f"{win_rate:.1f}%",
                        "Ù…Ù† Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§"
                    )
            
            with col4:
                if 'issue_area' in df.columns:
                    unique_issues = df['issue_area'].nunique()
                    display_metrics_card(
                        "Ù…Ø¬Ø§Ù„Ø§Øª Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§",
                        str(unique_issues),
                        "Ù†ÙˆØ¹ÙŠØ© Ù…Ø®ØªÙ„ÙØ©"
                    )
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            st.markdown("### ğŸ“‹ Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©")
            st.dataframe(df.head(10), use_container_width=True)
            
            # ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    quality_report = detect_data_quality(df)
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown("#### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©")
                        st.json({
                            'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§': quality_report['total_rows'],
                            'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©': quality_report['total_columns'],
                            'Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©': quality_report['missing_values'],
                            'Ù…ÙƒØ±Ø±Ø§Øª': quality_report['duplicates'],
                            'Ø­Ø¬Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø©': f"{quality_report['memory_usage']:.2f} MB"
                        })
                    
                    with col2:
                        st.markdown("#### ğŸ”¢ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                        st.json(quality_report['data_types'])
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    # ========== ØªØ¨ÙˆÙŠØ¨ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ ==========
    with tabs[1]:
        if st.session_state.anomalies is not None:
            anomalies_df = st.session_state.anomalies
            
            st.markdown('<div class="glass-card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</div>', unsafe_allow_html=True)
            
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø´Ø°ÙˆØ°
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                anomaly_count = anomalies_df['is_anomaly'].sum()
                display_metrics_card(
                    "Ù‚Ø¶Ø§ÙŠØ§ Ø´Ø§Ø°Ø©",
                    str(anomaly_count),
                    f"{(anomaly_count/len(anomalies_df))*100:.2f}%"
                )
            
            with col2:
                avg_anomaly_score = anomalies_df['anomaly_score_ensemble'].mean()
                display_metrics_card(
                    "Ù…ØªÙˆØ³Ø· Ø¯Ø±Ø¬Ø© Ø§Ù„Ø´Ø°ÙˆØ°",
                    f"{avg_anomaly_score:.3f}",
                    "0-1 (Ø£Ø¹Ù„Ù‰ = Ø´Ø§Ø°)"
                )
            
            with col3:
                if 'majority_votes' in anomalies_df.columns:
                    anomaly_votes = anomalies_df[anomalies_df['is_anomaly']]['majority_votes'].mean()
                    display_metrics_card(
                        "Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØµÙˆÙŠØª Ù„Ù„Ø´Ø§Ø°",
                        f"{anomaly_votes:.1f}",
                        "Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠ"
                    )
            
            with col4:
                if st.session_state.fraud_report:
                    corruption_score = st.session_state.fraud_report.get('corruption_score', 0)
                    display_metrics_card(
                        "Ù…Ø¤Ø´Ø± Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ",
                        f"{corruption_score:.1f}%",
                        "Ù†Ø³Ø¨Ø© Ø§Ù„Ø®Ø·ÙˆØ±Ø©"
                    )
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ø´Ø§Ø°Ø©
            st.markdown("### ğŸš¨ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©")
            anomalies_only = anomalies_df[anomalies_df['is_anomaly']]
            st.dataframe(anomalies_only, use_container_width=True)
            
            # ØªØµÙˆØ± Ø§Ù„Ø´Ø°ÙˆØ°
            st.markdown("### ğŸ“Š ØªØµÙˆØ± Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ")
            fig = create_anomaly_dashboard(anomalies_df, st.session_state.merged_df)
            if fig:
                st.plotly_chart(fig, use_container_width=True)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ
            if st.session_state.fraud_report:
                fraud_report = st.session_state.fraud_report
                
                st.markdown("### ğŸ•µï¸ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ")
                
                if fraud_report['fraud_indicators']:
                    for indicator in fraud_report['fraud_indicators']:
                        display_alert(
                            f"**{indicator['description']}**: {indicator['count']} Ø­Ø§Ù„Ø©",
                            type='warning' if indicator['count'] > 10 else 'info'
                        )
                else:
                    st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¤Ø´Ø±Ø§Øª ÙØ³Ø§Ø¯ ÙˆØ§Ø¶Ø­Ø©")
            
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ‘ˆ Ù‚Ù… Ø¨ØªØ´ØºÙŠÙ„ ÙƒØ´Ù Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ø§Ù‹")
    
    # ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯ ==========
    with tabs[2]:
        if st.session_state.model_pack is not None:
            model_pack = st.session_state.model_pack
            
            st.markdown('<div class="glass-card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">ğŸ¤– Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ</div>', unsafe_allow_html=True)
            
            # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                display_metrics_card(
                    "Ø§Ù„Ø¯Ù‚Ø©",
                    f"{model_pack['metrics']['accuracy']*100:.1f}%",
                    "Accuracy"
                )
            
            with col2:
                display_metrics_card(
                    "Precision",
                    f"{model_pack['metrics']['precision']*100:.1f}%",
                    "Ø¯Ù‚Ø© Ø§Ù„ØªÙ†Ø¨Ø¤"
                )
            
            with col3:
                display_metrics_card(
                    "Recall",
                    f"{model_pack['metrics']['recall']*100:.1f}%",
                    "ØªØºØ·ÙŠØ© Ø§Ù„Ø­Ø§Ù„Ø§Øª"
                )
            
            with col4:
                display_metrics_card(
                    "F1 Score",
                    f"{model_pack['metrics']['f1']*100:.1f}%",
                    "Ù…ØªÙˆØ³Ø· Ø§Ù„ÙˆØ²Ù†"
                )
            
            # Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª
            st.markdown("### ğŸ“Š Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤")
            fig = px.bar(
                model_pack['feature_importance'].head(10),
                x='importance',
                y='feature',
                orientation='h',
                title='Ø£Ù‡Ù… 10 Ù…ØªØºÙŠØ±Ø§Øª Ù…Ø¤Ø«Ø±Ø© ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯',
                color='importance',
                color_continuous_scale='Greens'
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # ØªÙ†Ø¨Ø¤Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
            st.markdown("### ğŸ”® ØªÙ†Ø¨Ø¤Ø§Øª Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø¬Ø¯ÙŠØ¯Ø©")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø¯Ø®Ø§Ù„ Ù„Ù„ØªÙ†Ø¨Ø¤
            input_data = {}
            cols = st.columns(3)
            
            for i, feature in enumerate(model_pack['feature_cols'][:6]):
                with cols[i % 3]:
                    if feature in st.session_state.merged_df.columns:
                        min_val = float(st.session_state.merged_df[feature].min())
                        max_val = float(st.session_state.merged_df[feature].max())
                        mean_val = float(st.session_state.merged_df[feature].mean())
                        
                        input_data[feature] = st.slider(
                            f"{feature}",
                            min_value=min_val,
                            max_value=max_val,
                            value=mean_val,
                            step=(max_val - min_val) / 100
                        )
            
            if st.button("ğŸ”® ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„ÙØ³Ø§Ø¯", use_container_width=True):
                # ØªØ¬Ù‡ÙŠØ² Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
                input_df = pd.DataFrame([input_data])
                
                # Ø§Ù„ØªÙ†Ø¨Ø¤
                prediction = model_pack['model'].predict(input_df)[0]
                probability = model_pack['model'].predict_proba(input_df)[0]
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                if prediction == 1:
                    display_alert(
                        f"âš ï¸ **Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© ÙØ³Ø§Ø¯ Ù‚Ø¶Ø§Ø¦ÙŠ Ø¹Ø§Ù„ÙŠØ©**: {probability[1]*100:.1f}%",
                        type='danger'
                    )
                else:
                    display_alert(
                        f"âœ… **Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© ÙØ³Ø§Ø¯ Ù‚Ø¶Ø§Ø¦ÙŠ Ù…Ù†Ø®ÙØ¶Ø©**: {probability[0]*100:.1f}%",
                        type='success'
                    )
            
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ‘ˆ Ù‚Ù… Ø¨ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ø£ÙˆÙ„Ø§Ù‹")
    
    # ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ ==========
    with tabs[3]:
        if st.session_state.legal_texts:
            st.markdown('<div class="glass-card">', unsafe_allow_html=True)
            st.markdown('<div class="card-title">âš–ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…</div>', unsafe_allow_html=True)
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ
            if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©", use_container_width=True):
                with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ..."):
                    analysis_results = analyze_legal_text(st.session_state.legal_texts)
                    
                    if 'wordcloud' in analysis_results:
                        st.markdown("### â˜ï¸ Word Cloud Ù„Ù„Ø£Ø­ÙƒØ§Ù…")
                        st.pyplot(analysis_results['wordcloud'])
                    
                    if 'top_words' in analysis_results:
                        st.markdown("### ğŸ“Š Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ø§Ù‹ ÙÙŠ Ø§Ù„Ø£Ø­ÙƒØ§Ù…")
                        words_df = pd.DataFrame(
                            analysis_results['top_words'][:20],
                            columns=['Ø§Ù„ÙƒÙ„Ù…Ø©', 'Ø§Ù„ØªÙƒØ±Ø§Ø±']
                        )
                        
                        fig = px.bar(
                            words_df,
                            x='Ø§Ù„ØªÙƒØ±Ø§Ø±',
                            y='Ø§Ù„ÙƒÙ„Ù…Ø©',
                            orientation='h',
                            color='Ø§Ù„ØªÙƒØ±Ø§Ø±',
                            color_continuous_scale='Greens'
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    
                    if 'sentiment' in analysis_results:
                        st.markdown("### ğŸ˜Š ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ø§Ø¹Ø± Ø§Ù„Ø£Ø­ÙƒØ§Ù…")
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("Polarity", f"{analysis_results['sentiment']['polarity']:.2f}")
                        with col2:
                            st.metric("Subjectivity", f"{analysis_results['sentiment']['subjectivity']:.2f}")
            
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLP
            if st.session_state.nlp_model is not None and st.session_state.justice_df is not None:
                st.markdown("### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙ†Ø§Ù‚Ø¶ Ø¨ÙŠÙ† Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ ÙˆØ§Ù„Ø£Ø­ÙƒØ§Ù…")
                
                if st.button("ğŸ§  ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…", use_container_width=True):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„ØªÙ†Ø§Ù‚Ø¶Ø§Øª..."):
                        sample_df = st.session_state.justice_df.head(20).copy()
                        
                        # Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯ Ø·ÙˆÙ„ Ø§Ù„Ù†Øµ
                        if 'facts' in sample_df.columns:
                            sample_df['facts_len'] = sample_df['facts'].astype(str).str.len()
                        
                        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
                        if 'first_party_winner' in sample_df.columns and 'facts' in sample_df.columns:
                            risk_scores = []
                            for idx, row in sample_df.iterrows():
                                crime_type = row.get('issue_area', 'Unknown')
                                risk = calculate_judicial_risk(
                                    row['facts'], 
                                    'In Favor' if row['first_party_winner'] else 'Against',
                                    str(crime_type),
                                    st.session_state.nlp_model
                                )
                                risk_scores.append(risk)
                            
                            sample_df['risk_score'] = risk_scores
                            
                            # Ø¹Ø±Ø¶ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ù…Ø®Ø§Ø·Ø±
                            high_risk = sample_df[sample_df['risk_score'] > 30]
                            if len(high_risk) > 0:
                                st.warning(f"ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(high_risk)} Ù‚Ø¶ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ù…Ø®Ø§Ø·Ø± Ø§Ù„ÙØ³Ø§Ø¯")
                                st.dataframe(high_risk[['docket', 'facts_len', 'first_party_winner', 'risk_score']])
                            
                            # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
                            if 'majority_votes' in sample_df.columns:
                                fig = px.scatter(
                                    sample_df, 
                                    x='facts_len', 
                                    y='majority_votes', 
                                    color='first_party_winner',
                                    size='risk_score',
                                    title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø·ÙˆÙ„ Ø§Ù„ÙˆÙ‚Ø§Ø¦Ø¹ ÙˆÙ‚Ø±Ø§Ø± Ø§Ù„ÙÙˆØ²",
                                    color_discrete_map={True: '#00ff88', False: '#ff4b4b'}
                                )
                                st.plotly_chart(fig, use_container_width=True)
                            
                            st.success("ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø¨Ù†Ø¬Ø§Ø­")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØµÙˆØµ
            st.markdown("### ğŸ“„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©")
            for i, text in enumerate(st.session_state.legal_texts[:5]):
                with st.expander(f"Ù†Øµ {i+1}"):
                    st.write(text)
            
            st.markdown('</div>', unsafe_allow_html=True)
        else:
            st.info("ğŸ‘ˆ Ù‚Ù… Ø¨Ø±ÙØ¹ Ù…Ù„Ù PDF Ø£Ùˆ TXT Ù…Ù† Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ Ù„Ù„ØªØ­Ù„ÙŠÙ„")
    
    # ========== ØªØ¨ÙˆÙŠØ¨ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ==========
    with tabs[4]:
        st.markdown('<div class="glass-card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">ğŸ“ˆ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©</div>', unsafe_allow_html=True)
        
        if st.session_state.merged_df is not None:
            # Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
            report_type = st.selectbox(
                "Ù†ÙˆØ¹ Ø§Ù„ØªÙ‚Ø±ÙŠØ±",
                ["ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶Ø§Ø©", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ†", "ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„"]
            )
            
            if report_type == "ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠ":
                st.markdown("### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØµÙÙŠØ© Ù„Ù„Ù‚Ø¶Ø§ÙŠØ§")
                st.dataframe(
                    st.session_state.merged_df.describe(include='all'),
                    use_container_width=True
                )
                
                # Ø®Ø±ÙŠØ·Ø© Ø­Ø±Ø§Ø±ÙŠØ©
                st.markdown("### ğŸ”¥ Ø®Ø±ÙŠØ·Ø© Ø§Ø±ØªØ¨Ø§Ø·Ø§Øª Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§")
                fig = create_correlation_heatmap(st.session_state.merged_df)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
            
            elif report_type == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù‚Ø¶Ø§Ø©":
                if 'justice' in st.session_state.merged_df.columns or 'ID' in st.session_state.merged_df.columns:
                    judge_col = 'justice' if 'justice' in st.session_state.merged_df.columns else 'ID'
                    
                    # ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø¶Ø§Ø©
                    judge_stats = st.session_state.merged_df.groupby(judge_col).agg({
                        'first_party_winner': ['mean', 'count'],
                        'majority_votes': 'mean'
                    }).round(2)
                    
                    judge_stats.columns = ['Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„', 'Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§', 'Ù…ØªÙˆØ³Ø· Ø§Ù„ØªØµÙˆÙŠØª']
                    judge_stats = judge_stats.sort_values('Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„', ascending=False)
                    
                    st.markdown("### ğŸ“Š Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù‚Ø¶Ø§Ø©")
                    st.dataframe(judge_stats, use_container_width=True)
                    
                    # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
                    fig = px.bar(
                        judge_stats.reset_index().head(10),
                        x=judge_col,
                        y='Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„',
                        title='Ø£Ø¹Ù„Ù‰ 10 Ù‚Ø¶Ø§Ø© ÙÙŠ Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„',
                        color='Ù†Ø³Ø¨Ø© ÙÙˆØ² Ø§Ù„Ø·Ø±Ù Ø§Ù„Ø£ÙˆÙ„',
                        color_continuous_scale='RdYlGn'
                    )
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù„Ù„Ù‚Ø¶Ø§Ø© ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            elif report_type == "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ†":
                if 'lawyer' in st.session_state.merged_df.columns:
                    # ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ†
                    lawyer_stats = st.session_state.merged_df.groupby('lawyer').agg({
                        'first_party_winner': ['mean', 'count']
                    }).round(2)
                    
                    lawyer_stats.columns = ['Ù†Ø³Ø¨Ø© Ø§Ù„ÙÙˆØ²', 'Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§']
                    lawyer_stats = lawyer_stats.sort_values('Ù†Ø³Ø¨Ø© Ø§Ù„ÙÙˆØ²', ascending=False)
                    
                    st.markdown("### ğŸ“Š Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ†")
                    st.dataframe(lawyer_stats, use_container_width=True)
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠÙ† Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡ÙŠÙ†
                    suspicious = lawyer_stats[lawyer_stats['Ù†Ø³Ø¨Ø© Ø§Ù„ÙÙˆØ²'] > 0.8]
                    if len(suspicious) > 0:
                        display_alert(
                            f"âš ï¸ ØªÙ… Ø§ÙƒØªØ´Ø§Ù {len(suspicious)} Ù…Ø­Ø§Ù…Ù Ø¨Ù†Ø³Ø¨Ø© ÙÙˆØ² Ù…Ø±ØªÙØ¹Ø© Ø¬Ø¯Ø§Ù‹ (>80%)",
                            type='warning'
                        )
                else:
                    st.warning("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø¹Ù…ÙˆØ¯ Ù„Ù„Ù…Ø­Ø§Ù…ÙŠÙ† ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
            
            elif report_type == "ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„":
                if st.button("ğŸ“Š Ø¥Ù†Ø´Ø§Ø¡ ØªÙ‚Ø±ÙŠØ± Ù‚Ø¶Ø§Ø¦ÙŠ Ø´Ø§Ù…Ù„", use_container_width=True):
                    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„..."):
                        # ØªÙ‚Ø±ÙŠØ± Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                        quality_report = detect_data_quality(st.session_state.merged_df)
                        
                        # ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø´Ø°ÙˆØ°
                        anomalies_df, _ = detect_anomalies_advanced(st.session_state.merged_df)
                        
                        # ØªÙ‚Ø±ÙŠØ± Ø§Ù„ÙØ³Ø§Ø¯
                        fraud_report = detect_fraud_patterns_judicial(st.session_state.merged_df)
                        
                        # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø±ÙŠØ±
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("#### ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠØ©")
                            st.json({
                                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù‚Ø¶Ø§ÙŠØ§': quality_report['total_rows'],
                                'Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©': quality_report['total_columns'],
                                'Ù‚ÙŠÙ… Ù…ÙÙ‚ÙˆØ¯Ø©': quality_report['missing_values'],
                                'Ù…ÙƒØ±Ø±Ø§Øª': quality_report['duplicates']
                            })
                            
                            st.markdown("#### ğŸš¨ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ")
                            st.json({
                                'Ù‚Ø¶Ø§ÙŠØ§ Ù…Ø´Ø¨ÙˆÙ‡Ø©': fraud_report['suspicious_cases'],
                                'Ø¯Ø±Ø¬Ø© Ø§Ù„ÙØ³Ø§Ø¯': f"{fraud_report['corruption_score']:.1f}%",
                                'Ù…Ø¤Ø´Ø±Ø§Øª Ù…ÙƒØªØ´ÙØ©': len(fraud_report['fraud_indicators'])
                            })
                        
                        with col2:
                            if anomalies_df is not None:
                                st.markdown("#### ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø°ÙˆØ° Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ")
                                st.json({
                                    'Ù‚Ø¶Ø§ÙŠØ§ Ø´Ø§Ø°Ø©': int(anomalies_df['is_anomaly'].sum()),
                                    'Ù†Ø³Ø¨Ø© Ø§Ù„Ø´Ø°ÙˆØ°': f"{(anomalies_df['is_anomaly'].sum()/len(anomalies_df))*100:.1f}%",
                                    'Ù…ØªÙˆØ³Ø· Ø¯Ø±Ø¬Ø© Ø§Ù„Ø´Ø°ÙˆØ°': f"{anomalies_df['anomaly_score_ensemble'].mean():.3f}"
                                })
                            
                            st.markdown("#### âš–ï¸ ØªÙˆØµÙŠØ§Øª Ù‚Ø¶Ø§Ø¦ÙŠØ©")
                            if fraud_report['corruption_score'] > 30:
                                st.error("Ù…Ø¤Ø´Ø± ÙØ³Ø§Ø¯ Ù‚Ø¶Ø§Ø¦ÙŠ Ù…Ø±ØªÙØ¹ - ÙŠÙ†ØµØ­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø¹Ø§Ø¬Ù„Ø© Ù„Ù„Ù‚Ø¶Ø§ÙŠØ§ Ø§Ù„Ù…Ø´Ø¨ÙˆÙ‡Ø©")
                            elif fraud_report['corruption_score'] > 15:
                                st.warning("Ù…Ø¤Ø´Ø± ÙØ³Ø§Ø¯ Ù‚Ø¶Ø§Ø¦ÙŠ Ù…ØªÙˆØ³Ø· - ÙŠØ­ØªØ§Ø¬ Ù…ØªØ§Ø¨Ø¹Ø© Ø¯Ù‚ÙŠÙ‚Ø©")
                            else:
                                st.success("Ù…Ø¤Ø´Ø± ÙØ³Ø§Ø¯ Ù‚Ø¶Ø§Ø¦ÙŠ Ù…Ù†Ø®ÙØ¶ - Ø£Ø¯Ø§Ø¡ Ù‚Ø¶Ø§Ø¦ÙŠ Ø¬ÙŠØ¯")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Ø§Ù„ÙÙˆØªØ±
    st.markdown("""
    <div class="footer">
        <h3>âš–ï¸ AI Judicial Audit System</h3>
        <p>Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ 2.0 | Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ù‚ÙˆÙ‚ Ù…Ø­ÙÙˆØ¸Ø© Â© 2026</p>
        <p style="margin-top: 1rem; font-size: 0.9rem;">
            Ù†Ø¸Ø§Ù… Ù…ØªÙƒØ§Ù…Ù„ Ù„ÙƒØ´Ù Ø§Ù„ÙØ³Ø§Ø¯ Ø§Ù„Ù‚Ø¶Ø§Ø¦ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø­Ø¯Ø« ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
